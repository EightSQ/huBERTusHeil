{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "91d77ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('rede_fraktion_preprocessed.csv')\n",
    "tops = df['top'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "67d5c313",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['top_id'] = df['top'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4afd0ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1850"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['top_id'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5d4656d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "df['top'] = df['top'].apply(lambda x: re.sub(r'Drucksache ([0-9]+)/([0-9]+)', '', x))\n",
    "df['top'] = df['top'].apply(lambda x: re.sub(r'(Befragung der Bundesregierung|Befragung|Fragestunde)', '', x))\n",
    "df_tops = df[['top', 'top_id']].drop_duplicates(subset=['top', 'top_id'])\n",
    "df_tops.index = np.arange(df_tops.shape[0])\n",
    "df_tops_to_ids = df[['top_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e8537aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279483</th>\n",
       "      <td>861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279484</th>\n",
       "      <td>861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279485</th>\n",
       "      <td>861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279486</th>\n",
       "      <td>861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279487</th>\n",
       "      <td>861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>279488 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        top_id\n",
       "0          237\n",
       "1          237\n",
       "2          237\n",
       "3          237\n",
       "4          237\n",
       "...        ...\n",
       "279483     861\n",
       "279484     861\n",
       "279485     861\n",
       "279486     861\n",
       "279487     861\n",
       "\n",
       "[279488 rows x 1 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tops_to_ids.to_csv('top_to_id ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e774b0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-11 16:31:23.053577: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-11 16:31:23.053614: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting de-core-news-md==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_md-3.1.0/de_core_news_md-3.1.0-py3-none-any.whl (47.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 47.8 MB 108 kB/s eta 0:00:01    |▎                               | 430 kB 2.5 MB/s eta 0:00:19\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /home/leon/.local/lib/python3.9/site-packages (from de-core-news-md==3.1.0) (3.1.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/leon/.local/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-md==3.1.0) (3.0.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/leon/.local/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-md==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/leon/.local/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-md==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-md==3.1.0) (2.11.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/leon/.local/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-md==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-md==3.1.0) (20.9)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.8 in /home/leon/.local/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-md==3.1.0) (8.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-md==3.1.0) (2.22.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-md==3.1.0) (57.1.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/leon/.local/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-md==3.1.0) (2.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/leon/.local/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-md==3.1.0) (4.62.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/leon/.local/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-md==3.1.0) (0.7.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /home/leon/.local/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-md==3.1.0) (2.0.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/leon/.local/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-md==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in /home/leon/.local/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-md==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/leon/.local/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-md==3.1.0) (1.0.5)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /home/leon/.local/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-md==3.1.0) (0.3.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/leon/.local/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-md==3.1.0) (1.19.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->de-core-news-md==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/leon/.local/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->de-core-news-md==3.1.0) (5.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/leon/.local/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->de-core-news-md==3.1.0) (3.7.4.3)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/leon/.local/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->de-core-news-md==3.1.0) (1.25.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/leon/.local/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->de-core-news-md==3.1.0) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->de-core-news-md==3.1.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->de-core-news-md==3.1.0) (2019.11.28)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /home/leon/.local/lib/python3.9/site-packages (from typer<0.4.0,>=0.3.0->spacy<3.2.0,>=3.1.0->de-core-news-md==3.1.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/lib/python3.9/site-packages (from jinja2->spacy<3.2.0,>=3.1.0->de-core-news-md==3.1.0) (1.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download de_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cda0e58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c35cfc0b841498f9da307e5b8cb32c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1776 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b2795b8c50643d892a8eb1c764c5a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('de_core_news_md')\n",
    "german_stop_words = stopwords.words('german')\n",
    "\n",
    "def stop_word_removal(x):\n",
    "    token = x.split()\n",
    "    return ' '.join([w for w in token if not w in german_stop_words])\n",
    "\n",
    "def lemmatization(x):\n",
    "    doc = nlp(x)\n",
    "    return ' '.join([x.lemma_ for x in doc])\n",
    "\n",
    "col = pd.Series(tops).apply(lambda x: stop_word_removal(x))\n",
    "\n",
    "processed_tops = []\n",
    "for x in tqdm(col):\n",
    "    processed_tops.append(lemmatization(x))\n",
    "    \n",
    "indexes = []\n",
    "result = []\n",
    "for i, x in tqdm(enumerate(processed_tops)):\n",
    "    tok = word_tokenize(x, language='german')\n",
    "    if len(tok) > 3:\n",
    "        indexes.append(i)\n",
    "        result.append(\" \".join(tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35116c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tops_processed.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump({\n",
    "    'tops': tops[indexes],\n",
    "    'processed': result\n",
    "}, 'tops_processed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26ff480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "data = joblib.load('tops_processed.pkl')\n",
    "tops = data['tops']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68cce18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tops = np.array(tops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c86d56e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fea85229",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = embed(tops).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7f50d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e8da30fe60451fa73f258849f1927a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "XX = PCA(n_components=2).fit_transform(enc)\n",
    "sns.scatterplot(x=XX[:, 0], y=XX[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db1d3d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30df4db3c0ea41a1a2e35d15cb77aa74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "c = AgglomerativeClustering(n_clusters=None, distance_threshold=0.75, affinity='cosine', linkage='average').fit_predict(enc)\n",
    "print(np.unique(c))\n",
    "\n",
    "XX = PCA(n_components=2).fit_transform(enc)\n",
    "plt.scatter(*XX.T)\n",
    "sns.scatterplot(x=XX[:, 0], y=XX[:, 1], hue=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9acc353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unabhängige Polizeibeschwerdestelle auf Bundesebene einrichten',\n",
       "       'Für ein Recht auf Anonymität im öffentlichen Raum – Keine automatisierte Gesichtserkennung durch die Bundespolizei Freiheit und Rechtsstaatlichkeit erhalten – Kein Einsatz biometrischer Gesichtserkennung in öffentlichen Räumen',\n",
       "       'Erfassung von Straftaten unter Zuhilfenahme des Tatmittels Messer in der Polizeilichen Kriminalstatistik',\n",
       "       ' Für ein Waffengesetz mit Augenmaß – Kein Generalverdacht gegen legale Waffenbesitzer Freiräume für Jäger und Sportschützen – Für eine schonende Umsetzung der EU-Feuerwaffenrichtlinie Tödliche Gefahr durch Schusswaffen eindämmen',\n",
       "       'Aktuelle Stunde Kommunalpolitiker, Polizei und Rettungskräfte vor Drohungen und Gewalt wirksam schützen',\n",
       "       'Aktuelle Stunde Erfolge bei der Bekämpfung der Kriminalität – Zahlen der Polizeilichen Kriminalstatistik 2018',\n",
       "       ' Für ein Recht auf Anonymität im öffentlichen Raum – Keine automatisierte Gesichtserkennung durch die Bundespolizei Freiheit und Rechtsstaatlichkeit erhalten – Kein Einsatz biometrischer Gesichtserkennung in öffentlichen Räumen Schnellstmögliche Beschaffung und Einführung von Distanz-Elektroimpulsgeräten für die Bundespolizei Digitalisierung der Polizeien und das Bundesprogramm Polizei 2020 zur politischen Chefsache erklären und unverzüglich umsetzen Gebührenverordnung zum Bundespolizeigesetz darf Grundrechtsgebrauch nicht beeinträchtigen',\n",
       "       ' Abschaffung der Zuverlässigkeitsüberprüfungen für Privatpiloten und Luftsportler Persönliche Eignung nach § 6 des Waffengesetzes wirksam gewährleisten',\n",
       "       'Bericht über das deutsche Engagement beim Einsatz von Polizistinnen und Polizisten in internationalen Polizeimissionen 2017 Ausbau des deutschen Polizeiengagements in internationalen Friedensmissionen voranbringen',\n",
       "       'Abschaffung der Zuverlässigkeitsüberprüfungen für Privatpiloten und Luftsportler',\n",
       "       'Persönliche Eignung nach § 6 des Waffengesetzes wirksam gewährleisten Waffenrecht mit Augenmaß und Konsequenz',\n",
       "       'Tödliche Gefahr durch Schusswaffen eindämmen Freiräume für Jäger und Sportschützen – Für eine schonende Umsetzung der EU-Feuerwaffenrichtlinie',\n",
       "       ' Für einen modernen und attraktiven Öffentlichen Dienst Polizeizulage wieder ruhegehaltsfähig gestalten',\n",
       "       'Auswirkungen des Coronavirus auf die Justiz – Virtuelle Gerichtsverhandlungen ermöglichen',\n",
       "       'Verfassungsfeindliche Tendenzen in der Polizei erkennen und entschlossen angehen  Unabhängige Polizeibeschwerdestelle auf Bundesebene einrichten Aufklärung polizeilichen Fehlverhaltens erleichtern – Ergänzung zum Entwurf eines Gesetzes über die unabhängige Polizeibeauftragte oder den unabhängigen Polizeibeauftragten des Bundes (Bundespolizeibeauftragtengesetz – BPolBeauftrG) Änderung der Geschäftsordnung des Deutschen Bundestages hier: Umsetzung des Gesetzes über die unabhängige Polizeibeauftragte oder den unabhängigen Polizeibeauftragten des Bundes (Bundespolizeibeauftragtengesetz – BPolBeauftrG)',\n",
       "       'Lehren aus den Gewaltexzessen in Stuttgart ziehen – Für eine Wende in der Migrations- und Sicherheitspolitik'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tops[c == 22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "186012e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vector_1, vector_2):\n",
    "    return np.dot(vector_1, vector_2)/(np.linalg.norm(vector_1) * np.linalg.norm(vector_2))\n",
    "\n",
    "def nearest_neighbor(v, candidates, k=1):\n",
    "    indices = np.argsort([cosine_similarity(v, row) for row in candidates])[-k:]\n",
    "    distances = [cosine_similarity(v, row) for row in candidates[indices]]\n",
    "    return indices, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fc7c7de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Auswirkungen der Afrikanischen Schweinepest auf die Agrar- und Ernährungswirtschaft'\n",
      " 'Nord Stream 2 die politische Unterstützung entziehen und den Bau stoppen Energiesicherheit gewährleisten – Nord Stream 2 unterstützen'\n",
      " 'Nachhaltige Entwicklungsziele erreichen – Potenziale aus der Agrarökologie anerkennen und unterstützen'\n",
      " 'Klimaziele verantwortungsbewusst erreichen Klimaziel 2020 einhalten statt verschieben – Zwanzig älteste Braunkohlekraftwerke unverzüglich abschalten Klimakonferenz in Bonn – Schneller Ausstieg aus der Kohle ist jetzt nötig Klimaschutzzusagen einhalten – An Zielen für 2020 festhalten Ausbau der Windenergie sichern, Klimaschutz voranbringen und Standort für Zukunftstechnologien erhalten'\n",
      " 'Bürgerenergie retten Stromstau auflösen anstatt erneuerbare Energien zu bremsen'\n",
      " 'Tschernobyl mahnt – Atomausstieg konsequent umsetzen'\n",
      " 'Wirksames Klimaschutzgesetz vorlegen – Maßnahmen und Regelungen für alle Sektoren UN-Klimakonferenz in Katowice 2018 – Pariser Klimaabkommen international unterstützen und in Deutschland umsetzen Klimaziel 2020 einhalten – Zwanzig älteste Braunkohlekraftwerke unverzüglich abschalten Klimakonferenz von Katowice – Pariser Klimaabkommen entschlossen umsetzen Klimagerechtigkeit global stärken – Energiewende und Kohleausstieg in Deutschland sozial gestalten Die 24. UN-Klimakonferenz für Weiterentwicklung marktbasierter Klimaschutzmechanismen nutzen Aufgabe der Energie- und Klimaschutz-Zwischenziele 2030 des Energiekonzeptes 2010 – Für eine faktenbasierte Klima- und Energiepolitik'\n",
      " 'Aktuelle Stunde Klimaschutz umsetzen – Haltung der Bundesregierung zu einer CO2-Abgabe'\n",
      " 'CO -Preise nicht den Mieterinnen und Mietern aufbürden Mit dem CO -Preis im Wärmebereich echte Lenkungswirkung erzielen'\n",
      " 'Mittelrheintal mit alternativer Gütertrasse und funktionierenden Ausweichstrecken entlasten'\n",
      " 'Energiesicherheit gewährleisten – Nord Stream 2 unterstützen'\n",
      " 'Aktuelle Stunde Wirtschaftliche Erholung nach der Coronakrise auf allen staatlichen Ebenen unterstützen'\n",
      " 'Unterstützung für das System Luftverkehr in Zeiten von Corona'\n",
      " 'Wohnungsbau entbürokratisieren – Kosten\\xadexplosion eindämmen'\n",
      " 'Aktuelle Stunde Steigende Strompreise stoppen – Energie bezahlbar machen'\n",
      " 'Pfand für Elektrogeräte und Batterien Wirtschaft entlasten – Treibhausgas-Emissionshandel gerade in der COVID-19-Wirtschaftskrise abschaffen'\n",
      " 'Stromsteuer senken – Bürger entlasten'\n",
      " 'Öffentlich-rechtlicher Vertrag zur Reduzierung und Beendigung der Braunkohleverstromung in Deutschland Einholung eines zustimmenden Beschlusses des Deutschen Bundestages gemäß § 49 des Kohleverstromungsbeendigungsgesetzes Modernste Kernenergie für Deutschland – Sicher, sauber und bezahlbar'\n",
      " ' Ein umfassendes Tabakwerbeverbot schaffen'\n",
      " 'Ein umfassendes Tabakwerbeverbot schaffen'\n",
      " 'Ein Forschungsrahmenprogramm im Kampf gegen die Klimakrise'\n",
      " 'Wälder schützen ‒ Rodungen für die Windkraft stoppen'\n",
      " 'Aussetzung des Ausstiegs aus der Kohle\\xadverstromung bis alternative Energien grundlastfähig sind und jederzeit bedarfsgerecht eingespeist werden können Die Europäische Union zur Klimaschutz-Union machen'\n",
      " 'Aktuelle Stunde Kohlekommission: Effektiven Klimaschutz sichern – Steuerzahler schützen'\n",
      " 'Klimakonferenz in Bonn – Schneller Ausstieg aus der Kohle ist jetzt nötig'\n",
      " 'Aktuelle Stunde Steuergelder für die Kohlekonzerne – Fragwürdige Berechnungen der Entschädigungszahlungen für die Braunkohlekraftwerke durch die Bundesregierung'\n",
      " 'Überfällige Überprüfung zur Einsparung von Kohlendioxid laut Strommarktgesetz vorlegen'\n",
      " 'Beschlussempfehlung und Bericht des Ausschusses für Wirtschaft und Energie (9. Ausschuss)  (neu)  (neu) Volkswirtschaftliche Fehlentwicklungen vermeiden – Kohleausstiegsgesetz zum Wohle der Bevölkerung stoppen Versorgungssicherheit gewährleisten – Kohleausstieg ablehnen Widerruf des Kohleausstiegs zur Verhinderung strukturpolitischer Fehlentwicklungen in den Kohlerevieren Strukturstärkungsgesetz Kohleregionen zukunftsfähig machen Deutschlands Klimagas-Budget als gerechten Beitrag zum Pariser Klimaschutzabkommen transparent machen Wirtschaftsstrukturen der Zukunft – Unternehmenscluster und regionale Kreisläufe in strukturschwachen Regionen etablieren'\n",
      " 'Widerruf des Kohleausstiegs zur Verhinderung strukturpolitischer Fehlentwicklungen in den Kohlerevieren'\n",
      " 'Nach den Empfehlungen der Kohlekommission – Jetzt Einstieg in den Kohleausstieg Deindustrialisierung Deutschlands stoppen – Ausstieg aus dem Kohleausstieg Kohleausstieg mit Verantwortung und Weitsicht – Sicher, bezahlbar und europäisch Kohleausstieg schnell und sozial gerecht umsetzen']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf78ec8b33e4759895da8c1524ee025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f479d239730>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "sentence = 'Kohleausstieg'\n",
    "e = embed([sentence]).numpy()[0]\n",
    "neighbor_indx, distances = nearest_neighbor(e, enc, k=30)\n",
    "print(tops[neighbor_indx])\n",
    "plt.plot(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fed12c0",
   "metadata": {},
   "source": [
    "## Load saved BERT (huBERTusHeil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5405b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "PRE_TRAINED_MODEL_NAME = 'bert-base-german-cased'\n",
    "\n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Create the BertClassfier class\n",
    "class BertClassifier(nn.Module):\n",
    "    \"\"\"Bert Model for Classification Tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self, freeze_bert=False):\n",
    "        \"\"\"\n",
    "        @param    bert: a BertModel object\n",
    "        @param    classifier: a torch.nn.Module classifier\n",
    "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
    "        \"\"\"\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        # Instantiate BERT model\n",
    "        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "\n",
    "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
    "        D_in, H, D_out = self.bert.config.hidden_size, 25, 7\n",
    "\n",
    "        # Instantiate an one-layer feed-forward classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(D_in, H),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(H, D_out)\n",
    "        )\n",
    "\n",
    "        # Freeze the BERT model\n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Feed input to BERT and the classifier to compute logits.\n",
    "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
    "                      max_length)\n",
    "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
    "                      information with shape (batch_size, max_length)\n",
    "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
    "                      num_labels)\n",
    "        \"\"\"\n",
    "        # Feed input to BERT\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "\n",
    "        # Feed input to classifier to compute logits\n",
    "        logits = self.classifier(last_hidden_state_cls)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def forward_latent(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Feed input to BERT and the classifier to compute logits.\n",
    "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
    "                      max_length)\n",
    "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
    "                      information with shape (batch_size, max_length)\n",
    "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
    "                      num_labels)\n",
    "        \"\"\"\n",
    "        # Feed input to BERT\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "\n",
    "        # Feed input to classifier to compute logits\n",
    "        return self.classifier[0](last_hidden_state_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9ab355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "def initialize_model(epochs=4):\n",
    "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
    "    \"\"\"\n",
    "    # Instantiate Bert Classifier\n",
    "    bert_classifier = BertClassifier(freeze_bert=False)\n",
    "\n",
    "    # Tell PyTorch to run the model on GPU\n",
    "    bert_classifier.to(device)\n",
    "\n",
    "    # Create the optimizer\n",
    "    optimizer = AdamW(bert_classifier.parameters(),\n",
    "                      lr=5e-5,    # Default learning rate\n",
    "                      eps=1e-8    # Default epsilon value\n",
    "                      )\n",
    "\n",
    "    # Total number of training steps\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    # Set up the learning rate scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=0, # Default value\n",
    "                                                num_training_steps=total_steps)\n",
    "    return bert_classifier, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801947b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "bert_classifier = BertClassifier(freeze_bert=False)\n",
    "bert_classifier.load_state_dict(torch.load(\"huBERTusHeil/20210809-1337-4epochs.pt\", map_location=torch.device(device)))\n",
    "bert_classifier.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9bb73e",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59dfd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "\n",
    "def preprocessing_for_bert(data):\n",
    "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
    "    @param    data (np.array): Array of texts to be processed.\n",
    "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
    "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
    "                  tokens should be attended to by the model.\n",
    "    \"\"\"\n",
    "    # Create empty lists to store outputs\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for i, d in tqdm(enumerate(data), total=data.shape[0]):\n",
    "        # `encode_plus` will:\n",
    "        #    (1) Tokenize the sentence\n",
    "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
    "        #    (3) Truncate/Pad sentence to max length\n",
    "        #    (4) Map tokens to their IDs\n",
    "        #    (5) Create attention mask\n",
    "        #    (6) Return a dictionary of outputs\n",
    "        #print(f'processing sample {i} of {len(data)}')\n",
    "        encoded = tokenizer.encode_plus(\n",
    "            text=d,  # Preprocess sentence\n",
    "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
    "            max_length=MAX_LEN,             # Max length to truncate/pad\n",
    "            pad_to_max_length=True,         # Pad sentence to max length\n",
    "            #return_tensors='pt',           # Return PyTorch tensor\n",
    "            return_attention_mask=True      # Return attention mask\n",
    "            )\n",
    "        \n",
    "        # Add the outputs to the lists\n",
    "        input_ids.append(encoded.get('input_ids'))\n",
    "        attention_masks.append(encoded.get('attention_mask'))\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks\n",
    "\n",
    "def get_latent_vector(model, input_ids, attention_mask):\n",
    "    # Feed input to BERT\n",
    "    outputs = model.bert(input_ids=input_ids,\n",
    "                        attention_mask=attention_mask)\n",
    "\n",
    "    # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "    last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "\n",
    "    # Feed input to first layer of classifier\n",
    "    return model.classifier[0](last_hidden_state_cls)\n",
    "def evaluate_latent_space(model, dataloader):\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    speeches = []\n",
    "    y_true = []\n",
    "\n",
    "    # For each batch in our validation set...\n",
    "    for batch in tqdm(dataloader):\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            vec = get_latent_vector(model, b_input_ids, b_attn_mask)\n",
    "\n",
    "        speeches.append(vec.cpu().numpy())\n",
    "        \n",
    "    # Compute the average accuracy and loss over the validation set.\n",
    "    return np.concatenate(speeches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea56c02",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb0725a",
   "metadata": {},
   "source": [
    "## Test Out the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad04ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "fractions = [\"AfD\", \"B90\", \"Union\", \"Linke\", \"FDP\", \"SPD\", \"fraktionslos\"]\n",
    "m = {x: i+1 for i, x in enumerate(fractions)}\n",
    "\n",
    "# tokenize and evaluate all speeches in partial_df\n",
    "def show_latent_space(partial_df):\n",
    "    input_ids, attention_masks = preprocessing_for_bert(partial_df['text'])\n",
    "    dataset = TensorDataset(input_ids, attention_masks)\n",
    "    data_sampler = SequentialSampler(dataset)\n",
    "    dataloader = DataLoader(dataset, sampler=data_sampler, batch_size=batch_size)\n",
    "    \n",
    "    latent = evaluate_latent_space(bert_classifier, dataloader)\n",
    "    labels = partial_df['fraktion'].map(m)\n",
    "    return latent, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1b9c3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "latent, labels = show_latent_space(df[:2000])\n",
    "XX = PCA(n_components=2).fit_transform(latent)\n",
    "palette = [\"#0000FF\", \"#00FF00\", \"#000000\", \"#EEEE00\",  \"#FF00FF\", \"#EE0000\", \"#CCCCCC\"]\n",
    "sns.scatterplot(x=XX[:, 0], y=XX[:, 1], hue=labels, palette=palette[:max(labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f5ebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "XX = PCA(n_components=2).fit_transform(latent)\n",
    "palette = [\"#0000FF\", \"#00FF00\", \"#000000\", \"#FF00FF\", \"#EEEE00\", \"#EE0000\", \"#CCCCCC\"]\n",
    "sns.scatterplot(x=XX[:, 0], y=XX[:, 1], hue=labels, palette=palette[:max(labels)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python39564bit5448324ed1e447b98959cbbfef4d39a8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
